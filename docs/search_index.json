[["index.html", "Statistical Modeling: A Tools Approach Chapter 1 Week 1: Maximum Likelihood 1.1 Class agenda 1.2 Maximum Likelihood", " Statistical Modeling: A Tools Approach Carlisle Rainey 2022-09-08 Chapter 1 Week 1: Maximum Likelihood 1.1 Class agenda Goal of the class Make you competent users and consumers (applied and methods papers) of methods beyond least-squares. I’m deliberately avoiding causal-inference methods (matching, DID, etc) because we have a class that covers those specifically that we’re offering regularly. I want you to learn a lot about specific tools, but also develop the skills to go and learn more on your own. We can deviate into any particular topic you’d find helpful. Structure of the class We have three sources of information that we’ll learn from: My lectures I have a set of tools that I want to introduce you to throughout the semester. I think of the lecture as offering “an overview” as well as “my take” on the tool. I will not supply all the details–we don’t have enough time and a lecture isn’t the ideal medium for deep and subtle ideas. In the past, I have supplied all of my lecture notes to students. However, the research seems clear that student note-taking boosts learning. Required readings For each topic, I have a few readings selected to supply further details or offer a different perspective. I want you to carefully read the required readings, even if they seem familiar. Suggested and other readings I encourage you to engage readings beyond the required set. These might be “easier” readings (e.g., FPP) or more difficult readings (e.g., Greene). In this category, I want you to use judgement. If the required readings are easy, then I recommend moving on after seriously engaging the required readings. If the required readings are too difficult, then seek out gentler introductions. You should NOT pursue the suggested or other readings at the expense of the required readings. Assessments This semester, we have a large set of tools that you must demonstrate that you (1) understand and (2) can implement. Exams: We will have regular exams that require you to implement and explain particular tools. I’m open to suggestions on frequency, but I suggest a weekly, open-book, take-home exam with about a one hour time limit. I will grade these as pass/fail. You can re-take a (slightly modified) exam up to three times if you fail. Journal: I want to you to journal throughout the semester. I want you to spend at least three hours (hopefully more most weeks) outside of class working on your journal. This journal should have several parts: Class Notes Review Exercises Notes from the required readings, including summaries, reactions, and (especially) questions or flags for ideas you didn’t understand. This latter is very important–it will make us all better. Notes from other readings. I want to give you a bit of space to explore things on your own. You could do a deeper dive on ideas covered carefully in the lectures or readings. Or you could pursue a tangential topic (but keep it somewhat related to class). Again, summaries, reactions, and questions are appropriate. I suggest engaging with reading from substantive course with this class in mind, and record your thoughts in your journal. Connections throughout the semester. Explorations of ideas for future projects. As I see it, “regression modeling” in political science is a several-step process: You begin with a substantive understanding of the way the world works. Choose a regression model. I introduce many. Fit a regression model. Maximum likelihood and Markov chain Monte Carlo methods are powerful and general. Evaluate the fit. What are the properties of the procedure? How well does the model match the data? Interpret the model. I emphasize quantities of interest and confidence intervals, but also discuss hypothesis tests. You then update your understanding of the world. This week, I introduce our first “engine”: maximum likelihood. As a starting point, we use ML to estimate the parameters of Bernoulli, Poisson, and beta distributions (without covariates). I introduce the parametric bootstrap as a tool to obtain confidence intervals. I introduce the invariance property and show how we can use the invariance property to transform the estimated parameters into other quantities of interest. To evaluate the models, we use the predictive distribution. 1.2 Maximum Likelihood Suppose we have a random sample from a distribution \\(f(x; \\theta)\\). We find the maximum likelihood (ML) estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) by maximizing the likelihood of the observed data with respect to \\(\\theta\\). In short, we take the likelihood of the data (given the model and a particular \\(\\theta\\)) and find the parameter \\(\\theta\\) that maximizes it. In practice, to make the math and/or computation a bit easier, we manipulate the likelihood function in two ways: Relabel the likelihood function \\(f(x; \\theta) = L(\\theta)\\), since it’s weird to maximize with respect to a “conditioning variable”fixed” variable. (The notation \\(f(x; \\theta)\\) suggests \\(x\\) varies for a particular \\(\\theta\\).) Work with \\(\\log L(\\theta)\\) rather than \\(L(\\theta)\\). Because \\(\\log()\\) is a monotonically increasing function, the \\(\\theta\\) that maximizes \\(L(\\theta)\\) also maximizes \\(\\log L(\\theta)\\). Suppose we have samples \\(x_1, x_2, ..., x_N\\) from \\(f(x; \\theta)\\). Then the joint density/probability is \\(f(x; \\theta) = \\prod_{n = 1}^N f(x_n; \\theta)\\) and \\(\\log L(\\theta) = \\sum_{n = 1}^N \\log \\left[ f(x_n; \\theta) \\right]\\). The ML estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) is \\(\\arg \\max \\log L(\\theta)\\). In applied problems, we might be able to simplify \\(\\log L\\) substantially. Occasionally, we can find a nice analytical maximum. In many cases, we have a computer find the parameter that maximizes \\(\\log L\\). 1.2.1 Example: Bernoulli Distribution As a running example, we use the toothpaste cap problem: We have a toothpaste cap–one with a wide bottom and a narrow top. We’re going to toss the toothpaste cap. It can either end up lying on its side, its (wide) bottom, or its (narrow) top. We want to estimate the probability of the toothpaste cap landing on its top. We can model each toss as a Bernoulli trial, thinking of each toss as a random variable \\(X\\) where \\(X \\sim \\text{Bernoulli}(\\pi)\\). If the cap lands on its top, we think of the outcome as 1. If not, as 0. Suppose we toss the cap \\(N\\) times and observe \\(k\\) tops. What is the ML estimate \\(\\hat{\\pi}\\) of \\(\\pi\\)? According to the model \\(f(x_i; \\pi) = \\pi^{x_i} (1 - \\pi)^{(1 - x_i)}\\). Because the samples are iid, we can find the joint distribution \\(f(x) = f(x_1) \\times ... \\times f(x_N) = \\prod_{i = 1}^N f(x_i)\\). We’re just multiplying \\(k\\) \\(\\pi\\)s (i.e., each of the \\(k\\) ones has probability \\(\\pi\\)) and \\((N - k)\\) \\((1 - \\pi)\\)s (i.e., each of the \\(N - k\\) zeros has probability \\(1 - \\pi\\)), so that the \\(f(x; \\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}\\). \\[ \\text{the likelihood: } f(x; \\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}, \\text{where } k = \\sum_{n = 1}^N x_n \\\\ \\] Then, we relabel. \\[ \\text{the likelihood: } L(\\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}\\\\ \\] Then, we take the log and simplify. \\[ \\text{the log-likelihood: } \\log L(\\pi) = k \\log (\\pi) + (N - k) \\log(1 - \\pi)\\\\ \\] To find the ML estimator, we find \\(\\hat{\\pi}\\) that maximizes \\(\\log L\\). The code below plots the log-likelihood function using the 8/150 data. pi &lt;- seq(0.01, 0.99, length.out = 1000) data &lt;- tibble(pi = pi) %&gt;% mutate(log_lik = 18*log(pi) + (150 - 8)*log(1 - pi)) ggplot(data, aes(x = pi, y = log_lik)) + geom_vline(xintercept = 8/150, color = &quot;green&quot;) + geom_line() + theme_minimal() In this case, the analytical optimum is easy. \\[ \\begin{aligned} \\frac{d \\log L}{d\\hat{\\pi}} = k \\left( \\frac{1}{\\hat{\\pi}}\\right) + (N - k) \\left( \\frac{1}{1 - \\hat{\\pi}}\\right)(-1) &amp;= 0\\\\ \\frac{k}{\\hat{\\pi}} - \\frac{N - y}{1 - \\hat{\\pi}} &amp;= 0 \\\\ \\frac{k}{\\hat{\\pi}} &amp;= \\frac{N - y}{1 - \\hat{\\pi}} \\\\ k(1 - \\hat{\\pi}) &amp;= (N - y)\\hat{\\pi} \\\\ k - y\\hat{\\pi} &amp;= N\\hat{\\pi} - y\\hat{\\pi} \\\\ k &amp;= N\\hat{\\pi} \\\\ \\hat{\\pi} &amp;= \\frac{k}{N} = \\text{avg}(x)\\\\ \\end{aligned} \\] The ML estimator of \\(\\pi\\) is the average of the \\(N\\) Bernoulli trials, or, equivalently, the fraction of successes. The collected data consist of 150 trials and 8 successes, so the ML estimate of \\(\\pi\\) is \\(\\frac{8}{150} \\approx 0.053\\). 1.2.2 Example: Poisson Distribution Suppose we collect \\(N\\) random samples \\(x = \\{x_1, x_2, ..., x_N\\}\\) and model each draw as a random variable \\(X \\sim \\text{Poisson}(\\lambda)\\). Find the ML estimator of \\(\\lambda\\). \\[ \\begin{aligned} \\text{Poisson likelihood: } f(x; \\lambda) &amp;= \\prod_{n = 1}^N \\frac{\\lambda^{x_n} e^{-\\lambda}}{x_n!} \\\\ L(\\lambda) &amp;= \\prod_{n = 1}^N \\frac{\\lambda^{x_n} e^{-\\lambda}}{x_n!} \\\\ \\log L(\\lambda) &amp;= \\sum_{n = 1}^N \\log \\left[ \\frac{\\lambda^{x_n} e^{-\\lambda}}{x_n!} \\right]\\\\ &amp;= \\sum_{n = 1}^N \\left[ x_n \\log \\lambda + (-\\lambda) \\log e - \\log x_n! \\right]\\\\ &amp;= \\log \\lambda \\left[ \\sum_{n = 1}^N x_n \\right] -N\\lambda + \\sum_{n = 1}^N \\log (x_n!) \\\\ \\end{aligned} \\] To find the ML estimator, we find \\(\\hat{\\lambda}\\) that maximizes \\(\\log L\\). In this case, the analytical optimum is easy. \\[ \\begin{aligned} \\frac{d \\log L}{d\\hat{\\lambda}} = \\frac{1}{\\hat{\\lambda}} \\left[ \\sum_{n = 1}^N x_n \\right] - N &amp;= 0\\\\ \\frac{1}{\\hat{\\lambda}} \\left[ \\sum_{n = 1}^N x_n \\right] &amp;= N \\\\ \\left[ \\sum_{n = 1}^N x_n \\right] &amp;= N \\hat{\\lambda} \\\\ \\hat{\\lambda} &amp;= \\frac{ \\sum_{n = 1}^N x_n }{N} = \\text{avg}(x) \\\\ \\end{aligned} \\] The ML estimator for the Poisson distribution is just the average of the samples. 1.2.3 Remarks The ML estimator is extremely common in political science because they are general, fast, and work extremely well. Lots of models that you’ve heard of, such as logistic regression, are estimated with ML. We can even obtain ML estimates for the linear regression model. We assume that the observed data are samples from a normal distribution with mean \\(\\mu_n = \\alpha + \\beta x_n\\) and variance \\(\\sigma^2\\). For this model, the least-squares estimate that we learned earlier is also the ML estimate. 1.2.4 Example: Beta Distribution Questions: What is the of the beta distribution? \\([0, 1]\\) Is \\(y\\) a discrete random variable or a continuous random variable? Continuous. What is the pdf/pmf? \\(f(y_i; \\alpha, \\beta) = \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\\), where \\(B(\\alpha, \\beta) = \\displaystyle \\int_0^1 t^{\\alpha - 1}(1 - t)^{\\beta - 1}dt\\). With the beta distribution, we add two complications that typically occur when using ML. multiple parameters an intractable log-likelihood Start with the probability model \\(Y_i \\sim f(y_i; \\theta)\\). In the case of the beta model, we have \\(Y_i \\sim \\text{beta}(y_i; \\alpha, \\beta)\\). The \\(\\alpha\\) and \\(\\beta\\) here don’t have a convenient interpretation. They are “shape” parameters. You can think of \\(\\alpha\\) as pushing the distribution to the right and \\(\\beta\\) as pushing the distribution to the left. alphas &lt;- c(0.8, 1, 2, 5, 25) betas &lt;- c(0.8, 1, 2, 5, 25) x &lt;- seq(0, 1, length.out = 100) pdfs &lt;- crossing(alpha = alphas, beta = betas, x = x) %&gt;% mutate(pdf = dbeta(x, alpha, beta)) %&gt;% mutate(alpha_lbl = paste0(&quot;alpha == &quot;, alpha), beta_lbl = paste0(&quot;beta == &quot;, beta)) ggplot(pdfs, aes(x = x, y = pdf)) + facet_grid(rows = vars(beta_lbl), cols = vars(alpha_lbl), labeller = &quot;label_parsed&quot;, scales = &quot;free&quot;) + geom_line() We now have two parameters to estimate and we’re going to assume that we have multiple observations, so that \\(y = [y_1, y_2, ,..., y_n]\\). In general, this is how we do ML: Step 1 Write down the likelihood function. Recall that we can obtain the joint density of \\(y_1\\) AND \\(y_2\\) AND … AND \\(y_n\\) by multiplying the probabilities of each (assuming independence). \\[ \\begin{aligned} L(\\alpha, \\beta) = \\displaystyle\\prod_{i = 1}^n \\overbrace{f(y_i;\\alpha, \\beta)}^{\\text{density}} = \\displaystyle\\prod_{i = 1}^n \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)} \\end{aligned} \\] We see again, as will be usual, that we have this complicated product that will make our lives difficult. Step 2 Take the log and simplify. \\[ \\begin{aligned} L(\\alpha, \\beta) &amp;= \\displaystyle\\prod_{i = 1}^n \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\\\\ \\log L(\\alpha, \\beta) &amp;= \\displaystyle\\sum_{i = 1}^n \\log \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\\\\ &amp;= \\displaystyle\\sum_{i = 1}^n \\left[ \\log y_i^{\\alpha - 1} + \\log (1 - y_i)^{\\beta - 1} - \\log B(\\alpha, \\beta)\\right]\\\\ &amp;= \\displaystyle\\sum_{i = 1}^n \\left[ (\\alpha - 1)\\log y_i + (\\beta - 1)\\log (1 - y_i) - \\log B(\\alpha, \\beta)\\right]\\\\ &amp;= \\displaystyle\\sum_{i = 1}^n \\left[ (\\alpha - 1)\\log y_i + (\\beta - 1)\\log (1 - y_i)\\right] - n \\log B(\\alpha, \\beta)\\\\ \\log L(\\alpha, \\beta) &amp;= (\\alpha - 1) \\sum_{i = 1}^n \\log y_i + (\\beta - 1) \\sum_{i = 1}^n \\log (1 - y_i) - n \\log B(\\alpha, \\beta) \\end{aligned} \\] Step 3 Maximize If we wanted, we could work on this one analytically. Take the derivative w.r.t. \\(\\alpha\\). Take the derivative w.r.t. \\(\\beta\\). Set both equal to zero and solve. (Two equations and two unknowns.) But the last term \\(B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1}(1 - t)^{\\beta - 1}dt\\) is tricky! So let’s do it numerically. To perform the optimization, we need a data set. For now, let’s simulate a fake data set with known parameters y &lt;- rbeta(1000, shape1 = 10, shape2 = 10) Let’s plot the log-likelihood function to see what we’re dealing with. library(plotly) alpha &lt;- seq(0.1, 25, length.out = 100) beta &lt;- seq(0.1, 25, length.out = 100) data &lt;- crossing(alpha, beta) %&gt;% mutate(log_lik = alpha*sum(log(y)) + beta*sum(log(1 - y)) - length(y)*log(beta(alpha, beta))) plot_ly(x = ~alpha, y = ~beta, z = ~log_lik, data = data) %&gt;% add_mesh(labels = c(&quot;alpha&quot;, &quot;beta&quot;, &quot;log-likelihood&quot;)) ggplot(data, aes(x = alpha, y = beta, z = log_lik)) + geom_contour(bins = 100) Now let’s program the log-likelihood function in R to handle the optimization numerically. ll_fn &lt;- function(theta, y) { alpha &lt;- theta[1] # optim() requires a single parameter vector beta &lt;- theta[2] ll &lt;- alpha*sum(log(y)) + beta*sum(log(1 - y)) - length(y)*log(beta(alpha, beta)) return(ll) } Now let’s use optim() to do the maximization. est &lt;- optim(par = c(1, 1), fn = ll_fn, y = y, control = list(fnscale = -1), method = &quot;Nelder-Mead&quot;) print(est$par, digits = 3) ## [1] 9.39 9.52 We can also wrap the optim() in a function, to make obtaining the estimates a little bit easier. est_beta &lt;- function(y) { est &lt;- optim(par = c(1, 1), fn = ll_fn, y = y, control = list(fnscale = -1), method = &quot;Nelder-Mead&quot;) # for &gt;1d problems if (est$convergence != 0) print(&quot;Model did not converge!&quot;) res &lt;- list(est = est$par) return(res) } ml_est &lt;- est_beta(y) print(ml_est, digits = 3) ## $est ## [1] 9.39 9.52 "],["week-2-bayesian-inference.html", "Chapter 2 Week 2: Bayesian Inference 2.1 Bayesian Inference 2.2 Example: Bernoulli 2.3 Example: Poisson Distribution 2.4 Remarks", " Chapter 2 Week 2: Bayesian Inference This week, we introduce the following tools. engine Bayesian inference distributions normal, uniform confidence intervals posterior simulation, Bayesian credible intervals, percentile intervals. quantities of interest transforming posterior simulations evaluating models posterior predictive distribution 2.1 Bayesian Inference Bayesian inference follows a simple recipe: Choose a distribution for the data. Choose a distribution to describe your prior beliefs. Update the prior distribution upon observing the data by computing the posterior distribution. In simple examples, we can implement this process analytically and obtain a closed-form posterior. In most applied cases, we can only sample from the posterior distribution, but this turns out to work almost as well. 2.1.1 Mechanics Suppose a random sample from a distribution \\(f(x; \\theta)\\) that depends on the unknown parameter \\(\\theta\\). Bayesian inference models our beliefs about the unknown parameter \\(\\theta\\) as a distribution. It answers the question: what should we believe about \\(\\theta\\), given the observed samples \\(x = \\{x_1, x_2, ..., x_n\\}\\) from \\(f(x; \\theta)\\)? These beliefs are simply the conditional distribution \\(f(\\theta \\mid x)\\). By Bayes’ rule, \\(\\displaystyle f(\\theta \\mid x) = \\frac{f(x \\mid \\theta)f(\\theta)}{f(x)} = \\frac{f(x \\mid \\theta)f(\\theta)}{\\displaystyle \\int_{-\\infty}^\\infty f(x \\mid \\theta)f(\\theta) d\\theta}\\). \\[ \\displaystyle \\underbrace{f(\\theta \\mid x)}_{\\text{posterior}} = \\frac{\\overbrace{f(x \\mid \\theta)}^{\\text{likelihood}} \\times \\overbrace{f(\\theta)}^{\\text{prior}}}{\\displaystyle \\underbrace{\\int_{-\\infty}^\\infty f(x \\mid \\theta)f(\\theta) d\\theta}_{\\text{normalizing constant}}} \\] There are four parts to a Bayesian analysis. \\(f(\\theta \\mid x)\\). “The posterior;” what we’re trying to find. This distribution models our beliefs about parameter \\(\\theta\\) given the data \\(x\\). \\(f(x \\mid \\theta)\\). “The likelihood.” This distribution model conditional density/probability of the data \\(x\\) given the parameter \\(\\theta\\). We need to invert the conditioning in order to find the posterior. \\(f(\\theta)\\). “The prior;” our beliefs about \\(\\theta\\) prior to observing the sample \\(x\\). \\(f(x) =\\int_{-\\infty}^\\infty f(x \\mid \\theta)f(\\theta) d\\theta\\). A normalizing constant. Recall that the role of the normalizing constant is to force the distribution to integrate or sum to one. Therefore, we can safely ignore this constant until the end, and then find proper normalizing constant. It’s convenient to choose a conjugate prior distribution that, when combined with the likelihood, produces a posterior from the same family as the prior. The resulting distribution is a complete and correct summary of our updated beliefs about the parameters. 2.1.2 Posterior Summaries If we want to summarize the posterior distribution, then we can (though we lose some information). First, we might summarize the distribution using a single point to make a “best guess” at the parameter of interest. We have three options: The posterior mean. The posterior mean minimizes a squared-error loss function. The posterior median: The posterior median minimizes an absolute loss function where the cost of guessing \\(a\\) when the truth is \\(\\alpha\\) is \\(|a - \\alpha|\\). Intuitively, there’s a 50% chance that \\(\\pi\\) falls above and below the posterior median. The posterior mode: The posterior mode is the most likely value of \\(\\pi\\), so it minimizes a loss function that penalizes all misses equally. Second, we might find an \\(100(1 - \\alpha)\\%\\) credible interval, by finding an interval that that integrates to \\((1 - \\alpha)\\). That is, a region that has a \\(100(1 - \\alpha)\\%\\) chance of containing the parameter. This interval is not unique; there are many. However, one \\(100(1 - \\alpha)\\%\\) credible interval is the \\(100(1 - \\alpha)\\%\\) percentile credible interval. Construct this interval by finding the \\(100\\frac{\\alpha}{2}th\\) percentile and the \\(100(1 - \\frac{\\alpha}{2})th\\) percentile. For example, if we want a 90% credible interval, we would find the 5th and 95th percentiles. 2.1.3 Posterior Simulation In some cases, we have an analytical solution for the posterior—we can write down the equation for the posterior. But in most cases, we cannot write down the posterior. Perhaps unexpectedly, it is usually easier to sample from the distribution that write down the posterior in closed form. But notice that the samples are almost as good as the closed-form solution. We can sample from the distribution many times and then draw the histogram, compute the average, and find the percentiles. Except for sampling error that we can make arbitraryily small, these correspond to the posterior density, the posterior mean, and the 95% (percentile) credible interval. 2.2 Example: Bernoulli As a running example, we use the toothpaste cap problem: We have a toothpaste cap–one with a wide bottom and a narrow top. We’re going to toss the toothpaste cap. It can either end up lying on its side, its (wide) bottom, or its (narrow) top. We want to estimate the probability of the toothpaste cap landing on its top. We can model each toss as a Bernoulli trial, thinking of each toss as a random variable \\(X\\) where \\(X \\sim \\text{Bernoulli}(\\pi)\\). If the cap lands on its top, we think of the outcome as 1. If not, as 0. Suppose we toss the cap \\(N\\) times and observe \\(k\\) tops. What is the posterior distribution of \\(\\pi\\)? 2.2.1 The Likelihood According to the model \\(f(x_i \\mid \\pi) = \\pi^{x_i} (1 - \\pi)^{(1 - x_i)}\\). Because the samples are iid, we can find the joint distribution \\(f(x) = f(x_1) \\times ... \\times f(x_N) = \\prod_{i = 1}^N f(x_i)\\). We’re just multiplying \\(k\\) \\(\\pi\\)s (i.e., each of the \\(k\\) ones has probability \\(\\pi\\)) and \\((N - k)\\) \\((1 - \\pi)\\)s (i.e., each of the \\(N - k\\) zeros has probability \\(1 - \\pi\\)), so that the \\(f(x | \\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}\\). \\[ \\text{the likelihood: } f(x | \\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}, \\text{where } k = \\sum_{n = 1}^N x_n \\\\ \\] 2.2.2 The Prior The prior describes your beliefs about \\(\\pi\\) before observing the data. Here are some questions that we might ask ourselves the following questions: What’s the most likely value of \\(\\pi\\)? Perhaps 0.15. Are our beliefs best summarizes by a distribution that’s skewed to the left or right? To the right. \\(\\pi\\) is about _____, give or take _____ or so. Perhaps 0.17 and 0.10. There’s a 25% chance that \\(\\pi\\) is less than ____. Perhaps 0.05. There’s a 25% chance that \\(\\pi\\) is greater than ____. Perhaps 0.20. Given these answers, we can sketch the pdf of the prior distribution for \\(\\pi\\). Now we need to find a density function that matches these prior beliefs. For this Bernoulli model, the beta distribution is the conjugate prior. While a conjugate prior is not crucial in general, it makes the math much more tractable. So then what beta distribution captures our prior beliefs? There’s a code snippet here to help you explore different beta distributions. After some exploration, I find that setting the parameters \\(\\alpha\\) and \\(\\beta\\) of the beta distribution to 3 and 15, respectively, captures my prior beliefs about the probability of getting a top. The pdf of the beta distribution is \\(f(x) = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1}(1 - x)^{\\beta - 1}\\). Remember that \\(B()\\) is the beta function, so \\(\\frac{1}{B(\\alpha, \\beta)}\\) is a constant. Let’s denote our chosen values of \\(\\alpha = 3\\) and \\(\\beta = 15\\) as \\(\\alpha^*\\) and \\(\\beta^*\\). As we see in a moment, it’s convenient distinguish the parameters in the prior distribution from other parameters. \\[ \\text{the prior: } f(\\pi) = \\frac{1}{B(\\alpha^*, \\beta^*)} \\pi^{\\alpha^* - 1}(1 - \\pi)^{\\beta^* - 1} \\] 2.2.3 The Posterior Now we need to compute the posterior by multiplying the likelihood times the prior and then finding the normalizing constant. \\[ \\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\overbrace{f(x \\mid \\pi)}^{\\text{likelihood}} \\times \\overbrace{f(\\pi)}^{\\text{prior}}}{\\displaystyle \\underbrace{\\int_{-\\infty}^\\infty f(x \\mid \\pi)f(\\pi) d\\pi}_{\\text{normalizing constant}}} \\\\ \\] Now we plug in the likelihood, plug in the prior, and denote the normalizing constant as \\(C_1\\) to remind ourselves that it’s just a constant. \\[ \\displaystyle f(\\pi \\mid x) = \\frac{\\left[ \\pi^{k} (1 - \\pi)^{(N - k) }\\right] \\times \\left[ \\frac{1}{B(\\alpha^*, \\beta^*)} \\pi^{\\alpha^* - 1}(1 - \\pi)^{\\beta^* - 1} \\right]}{ C_1} \\\\ \\] \\[ \\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\overbrace{\\left[ \\pi^{k} (1 - \\pi)^{(N - k) }\\right] }^{\\text{likelihood}} \\times \\overbrace{ \\left[ \\frac{1}{B(\\alpha^*, \\beta^*)} \\pi^{\\alpha^* - 1}(1 - \\pi)^{\\beta^* - 1} \\right] }^{\\text{prior}}}{\\displaystyle \\underbrace{C_1}_{\\text{normalizing constant}}} \\\\ \\] Now we need to simplify the right-hand side. First, notice that the term \\(\\frac{1}{B(\\alpha^*, \\beta^*)}\\) in the numerator is just a constant. We can incorporate that constant term with \\(C_1\\) by multiplying top and bottom by \\(B(\\alpha^*, \\beta^*)\\) and letting \\(C_2 = C_1 \\times B(\\alpha^*, \\beta^*)\\). \\[ \\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\overbrace{\\left[ \\pi^{k} (1 - \\pi)^{(N - k) }\\right] }^{\\text{likelihood}} \\times \\left[ \\pi^{\\alpha^* - 1}(1 - \\pi)^{\\beta^* - 1} \\right] }{\\displaystyle \\underbrace{C_2}_{\\text{new normalizing constant}}} \\\\ \\] Now we can collect the exponents with base \\(\\pi\\) and the exponents with base \\((1 - \\pi)\\). \\[ \\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\left[ \\pi^{k} \\times \\pi^{\\alpha^* - 1} \\right] \\times \\left[ (1 - \\pi)^{(N - k) } \\times (1 - \\pi)^{\\beta^* - 1} \\right] }{ C_2} \\\\ \\] Recalling that \\(x^a \\times x^b = x^{a + b}\\), we combine the powers. \\[ \\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\left[ \\pi^{(\\alpha^* + k) - 1} \\right] \\times \\left[ (1 - \\pi)^{[\\beta^* + (N - k)] - 1} \\right] }{ C_2} \\\\ \\] \\[ \\displaystyle f(\\theta \\mid x) = \\frac{f(x \\mid \\theta) \\times f(\\theta)}{\\displaystyle \\int_{-\\infty}^\\infty f(x \\mid \\theta)f(\\theta) d\\theta} \\] Because we’re clever, we notice that this is almost a beta distribution with \\(\\alpha = (\\alpha^* + k)\\) and \\(\\beta = [\\beta^* + (N - k)]\\). If \\(C_2 = B(\\alpha^* + k, \\beta^* + (N - k))\\), then the posterior is exactly a \\(\\text{beta}(\\alpha^* + k, \\beta^* + [N - k]))\\) distribution. This is completely expected. We chose a beta distribution for the prior because it would give us a beta posterior distribution. For simplicity, we can denote the parameter for the beta posterior as \\(\\alpha^\\prime\\) and \\(\\beta^\\prime\\), so that \\(\\alpha^\\prime = \\alpha^* + k\\) and \\(\\beta^\\prime = \\beta^* + [N - k]\\) \\[ \\begin{aligned} \\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} &amp;= \\frac{ \\pi^{\\overbrace{(\\alpha^* + k)}^{\\alpha^\\prime} - 1} \\times (1 - \\pi)^{\\overbrace{[\\beta^* + (N - k)]}^{\\beta^\\prime} - 1} }{ B(\\alpha^* + k, \\beta^* + [N - k])} \\\\ &amp;= \\frac{ \\pi^{\\alpha^\\prime - 1} \\times (1 - \\pi)^{\\beta^\\prime - 1} }{ B(\\alpha^\\prime, \\beta^\\prime)}, \\text{where } \\alpha^\\prime = \\alpha^* + k \\text{ and } \\beta^\\prime = \\beta^* + [N - k] \\end{aligned} \\] This is an elegant, simple solution. To obtain the parameters for the beta posterior distribution, we just add the number of tops (Bernoulli successes) to the prior value for \\(\\alpha\\) and the number of not-tops (sides and bottoms; Bernoulli failures) to the prior value for \\(\\beta\\). Suppose that I tossed the toothpaste cap 150 times and got 8 tops. # prior parameters alpha_prior &lt;- 3 beta_prior &lt;- 15 # data k &lt;- 8 N &lt;- 150 # posterior parameters alpha_posterior &lt;- alpha_prior + k beta_posterior &lt;- beta_prior + N - k # plot prior and posterior gg_prior &lt;- ggplot() + stat_function(fun = dbeta, args = list(shape1 = alpha_prior, shape2 = beta_prior)) + labs(title = &quot;prior distribution&quot;, x = &quot;pi&quot;, y = &quot;prior density&quot;) gg_posterior &lt;- ggplot() + stat_function(fun = dbeta, args = list(shape1 = alpha_posterior, shape2 = beta_posterior)) + labs(title = &quot;posterior distribution&quot;, x = &quot;pi&quot;, y = &quot;posterior density&quot;) library(patchwork) gg_prior + gg_posterior 2.2.4 Point Estimates The posterior mean. The posterior mean minimizes a squared-error loss function. That is, the cost of guessing \\(a\\) when the truth is \\(\\alpha\\) is \\((a - \\alpha)^2\\). In the case of the beta posterior, it’s just \\(\\dfrac{\\alpha^\\prime}{\\alpha^\\prime + \\beta^\\prime}\\). For our prior and data, we have \\(\\dfrac{3 + 8}{(3 + 8) + (15 + 150 - 8)} \\approx 0.065\\). The posterior median: The posterior median minimizes an absolute loss function where the cost of guessing \\(a\\) when the truth is \\(\\alpha\\) is \\(|a - \\alpha|\\). Intuitively, there’s a 50% chance that \\(\\pi\\) falls above and below the posterior median. In the case of the beta posterior, it’s just \\(\\dfrac{\\alpha^\\prime - \\frac{1}{3}}{\\alpha^\\prime + \\beta^\\prime - \\frac{2}{3}}\\) (for \\(\\alpha^\\prime, \\beta^\\prime &gt; 1\\)). For our prior and data, we have \\(\\dfrac{3 + 8 -\\frac{1}{3}}{(3 + k) + (15 + 150 - 8) - \\frac{2}{3}} \\approx 0.064\\). The posterior mode: The posterior mode is the most likely value of \\(\\pi\\), so it minimizes a loss function that penalizes all misses equally. In the case of the beta posterior, it’s just \\(\\dfrac{\\alpha^\\prime - 1}{\\alpha^\\prime + \\beta^\\prime - 2}\\) (for \\(\\alpha^\\prime, \\beta^\\prime &gt; 1\\)). For our prior and data, we have \\(\\dfrac{3 + 8 - 1}{(3 + k) + (15 + 150 - 8) - 2} \\approx 0.060\\). 2.2.5 Credible Interval Using the percentile method, we can compute the 90% and 95% credible intervals with qbeta(). # 90% credible interval qbeta(c(0.05, 0.95), 3 + 8, 15 + 150 - 8) ## [1] 0.03737493 0.09945329 # 95% credible interval qbeta(c(0.025, 0.975), 3 + 8, 15 + 150 - 8) ## [1] 0.03333712 0.10736323 2.2.6 Simulation We don’t need to use simulation here—we have the simple closed-form posterior. However, let’s see how simulation would work. post_sims &lt;- rbeta(1000, 3 + 8, 15 + 150 - 8) # posterior density gg_data &lt;- tibble(post_sims) ggplot(gg_data, aes(x = post_sims)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # posterior mean mean(post_sims) ## [1] 0.06558303 # credible interval 2.3 Example: Poisson Distribution Suppose we collect \\(N\\) random samples \\(x = \\{x_1, x_2, ..., x_N\\}\\) and model each draw as a random variable \\(X \\sim \\text{Poisson}(\\lambda)\\). Find the posterior distribution of \\(\\lambda\\) for the gamma prior distribution. Hint: the gamma distribution is the conjugate prior for the Poisson likelihood. \\[ \\begin{aligned} \\text{Poisson likelihood: } f(x \\mid \\lambda) &amp;= \\prod_{n = 1}^N \\frac{\\lambda^{x_n} e^{-\\lambda}}{x_n!} \\\\ &amp;= \\displaystyle \\left[ \\frac{1}{\\prod_{n = 1}^N x_n !} \\right]e^{-N\\lambda}\\lambda^{\\sum_{n = 1}^N x_n} \\end{aligned} \\] \\[ \\text{Gamma prior: } f( \\lambda; \\alpha^*, \\beta^*) = \\frac{{\\beta^*}^{\\alpha^*}}{\\Gamma(\\alpha^*)} \\lambda^{\\alpha^* - 1} e^{-\\beta^*\\lambda} \\] To find the posterior, we multiply the likelihood times the prior and normalize. Because the gamma prior distribution is the conjugate prior for the Poisson likelihood, we know that the posterior will be a gamma distribution. \\[ \\begin{aligned} \\text{Gamma posterior: } f( \\lambda \\mid x) &amp;= \\frac{\\left( \\displaystyle \\left[ \\frac{1}{\\prod_{n = 1}^N x_n !} \\right]e^{-N\\lambda}\\lambda^{\\sum_{n = 1}^N x_n}\\right) \\times \\left( \\left[ \\frac{{\\beta^*}^{\\alpha^*}}{\\Gamma(\\alpha^*)} \\right] \\lambda^{\\alpha^* - 1} e^{-\\beta^*\\lambda}\\right)}{C_1} \\\\ \\end{aligned} \\] Because \\(x\\), \\(\\alpha_*\\), and \\(\\beta\\) are fixed, the terms in square brackets are constant, so we can safely consider those part of the normalizing constant. \\[ \\begin{aligned} &amp;= \\frac{\\left( \\displaystyle e^{-N\\lambda}\\lambda^{\\sum_{n = 1}^N x_n}\\right) \\times \\left( \\lambda^{\\alpha^* - 1} e^{-\\beta^*\\lambda}\\right)}{C_2} \\\\ \\end{aligned} \\] Now we can collect the exponents with the same base. \\[ \\begin{aligned} &amp;= \\frac{\\left( \\lambda^{\\alpha^* - 1} \\times \\lambda^{\\sum_{n = 1}^N x_n}\\right) \\times \\left( \\displaystyle e^{-N\\lambda} \\times e^{-\\beta^*\\lambda} \\right)}{C_2} \\\\ &amp;= \\frac{\\lambda^{ \\overbrace{\\left[ \\alpha^* + \\sum_{n = 1}^N x_n \\right]}^{\\alpha^\\prime} - 1} e^{-\\overbrace{[\\beta^* + N]}^{\\beta^\\prime}\\lambda} }{C_2} \\\\ \\end{aligned} \\] We recognize this as almost a Gamma distribution with parameters \\(\\alpha^\\prime = \\alpha^* + \\sum_{n = 1}^N x_n\\) and \\(\\beta^\\prime = \\beta^* + N\\). Indeed, if \\(\\frac{1}{C_2} = \\frac{{\\beta^\\prime}^{\\alpha^\\prime}}{\\Gamma(\\alpha^{\\prime})}\\), then we have exactly a gamma distribution. \\[ \\begin{aligned} &amp;= \\frac{{\\beta^\\prime}^{\\alpha^\\prime}}{\\Gamma(\\alpha^{\\prime})} \\lambda^{ \\alpha^\\prime - 1} e^{-\\beta^\\prime\\lambda}, \\text{where } \\alpha^\\prime = \\alpha^* + \\sum_{n = 1}^N x_n \\text{ and } \\beta^\\prime = \\beta^* + N \\end{aligned} \\] Like the Bernoulli likelihood with the beta prior, the Poisson likelihood withe the gamma prior gives a nice result. We start with values parameters of the gamma distribution \\(\\alpha = \\alpha^*\\) and \\(\\beta + \\beta^*\\) so that the gamma prior distribution describes our prior beliefs about the parameters \\(\\lambda\\) of the Poisson distribution. Then we add the sum of the data \\(x\\) to \\(\\alpha^*\\) and the number of samples \\(N\\) to \\(\\beta^*\\) to obtain the parameters of the gamma posterior distribution. The code below shows the posterior distribution # set see to make reproducible set.seed(1234) # prior parameters alpha_prior &lt;- 3 beta_prior &lt;- 3 # create an &quot;unknown&quot; value of lambda to estimate lambda &lt;- 2 # generate a data set N &lt;- 5 # number of samples x &lt;- rpois(N, lambda = lambda) print(x) # print the data set ## [1] 0 2 2 2 4 # posterior parameters alpha_posterior &lt;- alpha_prior + sum(x) beta_posterior &lt;- beta_prior + N # plot prior and posterior gg_prior &lt;- ggplot() + xlim(0, 5) + stat_function(fun = dgamma, args = list(shape = alpha_prior, rate = beta_prior)) + labs(title = &quot;prior distribution&quot;, x = &quot;lambda&quot;, y = &quot;prior density&quot;) gg_posterior &lt;- ggplot() + xlim(0, 5) + stat_function(fun = dgamma, args = list(shape = alpha_posterior, rate = beta_posterior)) + labs(title = &quot;posterior distribution&quot;, x = &quot;lambda&quot;, y = &quot;posterior density&quot;) gg_prior + gg_posterior # uses patchwork package # posterior mean: alpha/beta alpha_posterior/beta_posterior ## [1] 1.625 # posterior mode: (alpha - 1)/beta for alpha &gt; 1 (alpha_posterior - 1)/beta_posterior ## [1] 1.5 # 90% credible interval qgamma(c(0.05, 0.95), alpha_posterior, beta_posterior) ## [1] 0.9611973 2.4303212 # 95% credible interval qgamma(c(0.025, 0.975), alpha_posterior, beta_posterior) ## [1] 0.8652441 2.6201981 In the case of the posterior median, there is no closed-form solution, even though we know the form of the posterior. We can use simulation to obtain the median. # posterior median: no closed form, so simulate post_sims &lt;- rgamma(1000, alpha_posterior, beta_posterior) median(post_sims) ## [1] 1.59919 2.4 Remarks Bayesian inference presents two difficulties. Choosing a prior. It can be hard to actually construct a prior distribution. It’s challenging when dealing with a single parameter. It becomes much more difficult when dealing with several or many parameters. Priors are subjective, so that one researcher’s prior might not work for another. Computing the posterior. Especially for many-parameter problems and non-conjugate priors, computing the posterior can be nearly intractable. However, there are several practical solutions to these difficulties. Choosing a prior. We can use a “uninformative” or constant prior. Sometimes, we can use an improper prior that doesn’t integrate to one, but places equal prior weight on all values. We can use an extremely diffuse prior. For example, if we wanted to estimate the average height in a population in inches, we might use a normal distribution centered at zero with an SD of 10,000. This prior says: “The average height is about zero, give or take 10,000 inches or so.” We can use an informative prior, but conduct careful robustness checks to assess whether the conclusions depend on the particular prior. We can use a weakly informative prior, that rules places meaningful prior weight on all the plausible values and little prior weight only on the most implausible values. As a guideline, you might create a weakly informative prior by doubling or tripling the SD of the informative prior. Computing the posterior. While analytically deriving the posterior becomes intractable for most applied problems, it’s relatively easy to sample from the posterior distribution for many models. Algorithms like Gibbs samplers, MCMC, and HMC make this sampling procedure straightforward for a given model. Software such as Stan make sampling easy to set up and very fast. Post-processing R packages such as tidybayes make it each to work with the posterior simulations. "],["week-3-adding-predictors.html", "Chapter 3 Week 3: Adding Predictors 3.1 Review: The Normal Model 3.2 Quantities of Interest", " Chapter 3 Week 3: Adding Predictors So far, we have discussed several major ideas: Maximum likelihood to obtain point estimates of model parameters and the invariance property to transform those estimates into quantities of interest. In this framework, we can use the parametric bootstrap to create confidence intervals and the predictive distribution to understand fitted models. Bayesian inference to obtain posterior beliefs (i.e., distributions) of model parameters. In most applied cases, we will simulate from the posterior. We can transform those simulations to obtain posterior distributions of the quantities of interest. We can use the posterior predictive distribution to understand the fit. We’ve discussed the tools above in the context of the Bernoulli, Poisson, and exponential models. Using the toothpaste cap, binary survey responses, civilian casualties, and government survival data. Today, we’re going to focus on two narrow parts of models and explore how two current tools generalize to the regression context. The linear predictor \\(X\\beta\\). The inverse link function. How the [posterior] predictive distribution generalizes to regression. How quantities of interest generalize to regression. For this week, we’ll need the following packages: rstan/rstanarm tidybayes Zelig; devtools::install_github('IQSS/Zelig') 3.1 Review: The Normal Model To fix ideas, we are going to re-develop the linear model from POS 5746. We imagine a continuous outcome \\(y = \\{y_1, y_1,..., y_n\\}\\) and a set of predictors or “explanatory variables” \\(x_1 = \\{x_{11}, x_{21}, ..., x_{n1}\\}, x_2 = \\{x_{12}, x_{22}, ..., x_{n2}\\}, ..., x_k = \\{x_{1k}, x_{2k}, ..., x_{nk}\\}\\). The notation \\(y_i\\) refers to the \\(i\\)th observation of the outcome variable. The notation \\(x_{ij}\\) refers to the \\(i\\)th observation of the \\(j\\)th control variable. The we write the linear regression model as \\[ y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_k x_{ik} + r_i. \\] We might then assume that the \\(r_i\\)s follow a normal distribution, so that \\(r_i \\sim N(0, \\sigma^2)\\) for all \\(i\\). The we can define \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_k x_{ik}\\) and see that \\[ y_i \\sim N(\\mu_i, \\sigma^2). \\] Taking the expectation, we have \\(E(y_i \\mid x_1, x_2, ... , x_n) = \\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_k x_{ik}\\). This is just a conditional average (the average of the outcome conditional on the explanatory variables). Sometimes we refer to this quantity as \\(\\hat{y}_i\\). There are two important features of this model that I want to explore: the distribution or “stochastic component” and the linear predictor of the model. 3.1.1 Distribution This model uses the normal distribution to describe the unexplained variation in \\(y_i - \\hat{y}_i\\). POS 5746 focuses (mostly) on models that assume a normal distribution for the outcome. King (1998) calls this the “stochastic” component of the model. For now, simply note that we are not restricted to a normal model, we could easily adapt the model to use a Bernoulli, exponential, or Poisson distribution, for example. 3.1.2 Linear Predictor The linear predictor \\(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_k x_{ik}\\) is critically important. So we should spend some time to get familiar with it. For the sake of this exercise, the values of the \\(\\beta\\)s and the \\(x_{ij}\\)s are arbitrary, # devtools::install_github(&#39;IQSS/Zelig&#39;) data(macro, package = &quot;Zelig&quot;) set.seed(1234) small_macro &lt;- macro %&gt;% select(unem, gdp, capmob, trade) %&gt;% sample_n(5) %&gt;% mutate(across(.fns = signif, digits = 2)) kableExtra::kable(small_macro, format = &quot;markdown&quot;) unem gdp capmob trade 284 1.5 5.2 -1 88 336 2.0 4.8 -1 27 101 2.7 3.2 -2 74 111 6.8 5.3 0 94 133 2.6 5.4 -1 33 fit &lt;- lm(unem ~ gdp + capmob + trade, data = small_macro) signif(coef(fit), digits = 2) ## (Intercept) gdp capmob trade ## 19.0000 -2.4000 4.5000 0.0027 In-Class Exercise For the \\(\\beta\\)s and the \\(x_{ij}\\)s above, compute each \\(\\mu_i\\) and \\(r_i = y_i - \\mu_i\\). Now, let’s bind the explanatory variables into a matrix, so that \\[ X = [x_1, x_2, ..., x_k] = \\begin{bmatrix} x_{11} &amp; x_{12} &amp;\\dots &amp; x_{1k}\\\\ x_{21} &amp; x_{22} &amp;\\dots &amp; x_{2k}\\\\ \\vdots &amp; \\vdots &amp;\\ddots &amp; \\vdots\\\\ x_{n1} &amp; x_{n2} &amp; \\dots &amp; x_{nk} \\end{bmatrix}. \\] And let’s bind the \\(\\beta\\)s into a column-vector, so that \\[ \\beta = \\begin{bmatrix} \\beta_{1} \\\\ \\beta_{2} \\\\ \\vdots\\\\ \\beta_{k} \\end{bmatrix}. \\] \\(\\beta = [\\beta_0, \\beta_1, \\beta_2, ..., \\beta_k]\\). Notice that we have a \\(n \\times (k + 1)\\) matrix \\(X\\) and a \\((k + 1) x 1\\) matrix \\(\\beta\\). I content that the matrix multiplication \\(\\mu = X\\beta\\) is identical to \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_k x_{ik}\\). In-Class Exercise For the \\(\\beta\\)s and the \\(x_{ij}\\)s above, compute each \\(\\mu = X\\beta\\) and \\(r = y - \\mu\\). We can confirm with R. y &lt;- small_macro$unem X &lt;- cbind(1, small_macro$gdp, small_macro$capmob, small_macro$trade) print(X) ## [,1] [,2] [,3] [,4] ## [1,] 1 5.2 -1 88 ## [2,] 1 4.8 -1 27 ## [3,] 1 3.2 -2 74 ## [4,] 1 5.3 0 94 ## [5,] 1 5.4 -1 33 beta &lt;- matrix(signif(coef(fit), digits = 2), ncol = 1) print(beta) ## [,1] ## [1,] 19.0000 ## [2,] -2.4000 ## [3,] 4.5000 ## [4,] 0.0027 mu &lt;- X%*%beta; mu ## [,1] ## [1,] 2.2576 ## [2,] 3.0529 ## [3,] 2.5198 ## [4,] 6.5338 ## [5,] 1.6291 r &lt;- small_macro$unem - mu; r ## [,1] ## [1,] -0.7576 ## [2,] -1.0529 ## [3,] 0.1802 ## [4,] 0.2662 ## [5,] 0.9709 From now on, we can just write… \\(X_i\\beta\\) rather than \\(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_k x_{ik}\\) (returns a scalar \\(\\mu_i\\)) \\(X\\beta\\) rather than \\(\\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\beta_k x_{k}\\) (returns a vector \\(\\mu\\)) 3.1.3 Fitting the Normal-Linear Model 3.1.3.1 Maximum Likelihood It turns out that the usual least-squares solution from POS 5746 is the maximum likelihood estimate of \\(\\beta\\). And the RMS of the residuals is the ML estimator of \\(\\sigma\\). beta_hat &lt;- solve(t(X)%*%X)%*%t(X)%*%y print(beta_hat, digits = 2) ## [,1] ## [1,] 18.8277 ## [2,] -2.3766 ## [3,] 4.5184 ## [4,] 0.0027 sigma_hat &lt;- sqrt(sum((y - X%*%beta_hat)^2)) print(sigma_hat, digits = 2) ## [1] 1.6 fit &lt;- lm(unem ~ gdp + capmob + trade, data = small_macro) arm::display(fit) ## lm(formula = unem ~ gdp + capmob + trade, data = small_macro) ## coef.est coef.se ## (Intercept) 18.83 11.64 ## gdp -2.38 1.77 ## capmob 4.52 2.33 ## trade 0.00 0.03 ## --- ## n = 5, k = 4 ## residual sd = 1.64, R-Squared = 0.85 We can get confidence intervals with the parametric bootstrap. # get ml estimates fit &lt;- lm(unem ~ gdp + capmob + trade, data = small_macro) mu_hat &lt;- predict(fit) # same as X%*%beta_hat sigma_hat &lt;- sqrt(sum(residuals(fit)^2)) # do parametric bootstrap n_bs &lt;- 100 bs_est &lt;- matrix(NA, ncol = length(coef(fit)), nrow = n_bs) for (i in 1:n_bs) { bs_y &lt;- rnorm(nrow(small_macro), mean = mu_hat, sd = sigma_hat) bs_fit &lt;- update(fit, bs_y ~ .) bs_est[i, ] &lt;- coef(bs_fit) } # compute the quantiles for each coef apply(bs_est, 2, quantile, probs = c(0.05, 0.95)) ## [,1] [,2] [,3] [,4] ## 5% 0.6518702 -4.9998081 1.690274 -0.04557350 ## 95% 35.5920062 0.4865889 7.987606 0.06363354 3.1.3.2 Bayesian The stan_glm() function allows us to easily get posterior simulations for the coefficients (and \\(\\sigma\\)) for the normal linear model. library(rstanarm); options(mc.cores = parallel::detectCores()) stan_fit &lt;- stan_glm(unem ~ gdp + capmob + trade, data = small_macro, family = &quot;gaussian&quot;, chains = 1, prior = NULL, prior_intercept = NULL) print(stan_fit) ## stan_glm ## family: gaussian [identity] ## formula: unem ~ gdp + capmob + trade ## observations: 5 ## predictors: 4 ## ------ ## Median MAD_SD ## (Intercept) 19.3 11.7 ## gdp -2.4 1.7 ## capmob 4.5 2.3 ## trade 0.0 0.0 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 1.8 0.9 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 3.1.4 Applied Example # load data cg &lt;- read_csv(&quot;data/parties.csv&quot;) %&gt;% glimpse() ## Rows: 555 ## Columns: 10 ## $ country &lt;chr&gt; &quot;Albania&quot;, &quot;Albania&quot;, &quot;Albania&quot;, &quot;Argentina&quot;, &quot;Ar… ## $ year &lt;dbl&gt; 1992, 1996, 1997, 1946, 1951, 1954, 1958, 1960, 1… ## $ average_magnitude &lt;dbl&gt; 1.00, 1.00, 1.00, 10.53, 10.53, 4.56, 8.13, 4.17,… ## $ eneg &lt;dbl&gt; 1.106929, 1.106929, 1.106929, 1.342102, 1.342102,… ## $ enep &lt;dbl&gt; 2.190, 2.785, 2.870, 5.750, 1.970, 1.930, 2.885, … ## $ upper_tier &lt;dbl&gt; 28.57, 17.86, 25.80, 0.00, 0.00, 0.00, 0.00, 0.00… ## $ en_pres &lt;dbl&gt; 0.00, 0.00, 0.00, 2.09, 1.96, 1.96, 2.65, 2.65, 3… ## $ proximity &lt;dbl&gt; 0.00, 0.00, 0.00, 1.00, 1.00, 0.20, 1.00, 0.20, 1… ## $ social_heterogeneity &lt;chr&gt; &quot;Bottom 3rd of ENEG&quot;, &quot;Bottom 3rd of ENEG&quot;, &quot;Bott… ## $ electoral_system &lt;chr&gt; &quot;Single-Member District&quot;, &quot;Single-Member District… # fitting model with ls/ml f &lt;- enep ~ eneg*log(average_magnitude) + eneg*upper_tier + en_pres*proximity fit &lt;- lm(f, data = cg) arm::display(fit, detail = TRUE) ## lm(formula = f, data = cg) ## coef.est coef.se t value Pr(&gt;|t|) ## (Intercept) 2.81 0.20 14.31 0.00 ## eneg 0.19 0.08 2.47 0.01 ## log(average_magnitude) 0.33 0.11 2.88 0.00 ## upper_tier 0.05 0.01 4.98 0.00 ## en_pres 0.35 0.07 4.84 0.00 ## proximity -3.42 0.38 -8.98 0.00 ## eneg:log(average_magnitude) 0.08 0.06 1.28 0.20 ## eneg:upper_tier -0.02 0.00 -3.37 0.00 ## en_pres:proximity 0.80 0.15 5.34 0.00 ## --- ## n = 555, k = 9 ## residual sd = 1.59, R-Squared = 0.30 # fitting model with Stan fit &lt;- stan_glm(f, data = cg, chains = 1) print(fit) ## stan_glm ## family: gaussian [identity] ## formula: enep ~ eneg * log(average_magnitude) + eneg * upper_tier + en_pres * ## proximity ## observations: 555 ## predictors: 9 ## ------ ## Median MAD_SD ## (Intercept) 2.8 0.2 ## eneg 0.2 0.1 ## log(average_magnitude) 0.3 0.1 ## upper_tier 0.0 0.0 ## en_pres 0.3 0.1 ## proximity -3.4 0.4 ## eneg:log(average_magnitude) 0.1 0.1 ## eneg:upper_tier 0.0 0.0 ## en_pres:proximity 0.8 0.1 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 1.6 0.0 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 3.2 Quantities of Interest We’ve now got three models: the normal model the logit model the Poisson model In only the case of the normal distribution are the parameters directly interpretable. The meaning of the coefficients in the case of the logit and Poisson model is especially unclear. Thus, we are interested not in the coefficients themselves, but in other “quantities of interest.” 3.2.1 Expected Value The first quantity of interest is the expected value \\(E(y \\mid X_s)\\). Imagine a particular scenario of interest \\(X_s\\). For the logit model, we can compute the expected value of \\(y\\) for that scenario using \\(\\hat{E}(y \\mid X_p) = \\hat{\\pi}_s = \\text{logit}^{-1}(X_s\\hat{\\beta})\\). For the Poisson model, it’s \\(\\hat{E}(y \\mid X_p) = \\hat{\\lambda}_s = e^{X_s\\hat{\\beta}}\\). Let’s see how this would work with the scobit data. scobit &lt;- haven::read_dta(&quot;data/scobit.dta&quot;) %&gt;% filter(newvote != -1) f &lt;- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov fit &lt;- glm(f, data = scobit, family = binomial) First, let’s create the scenario of interest. # create the scenario of interest X_s (but a data frame) scenario &lt;- tibble( neweduc = median(scobit$neweduc), closing = median(scobit$closing), age = median(scobit$age), south = median(scobit$south), gov = median(scobit$gov)) %&gt;% glimpse() ## Rows: 1 ## Columns: 5 ## $ neweduc &lt;dbl&gt; 5 ## $ closing &lt;dbl&gt; 30 ## $ age &lt;dbl&gt; 40 ## $ south &lt;dbl&gt; 0 ## $ gov &lt;dbl&gt; 0 # now use the predict() function to get pi_hat pi_hat &lt;- predict(fit, newdata = scenario, type = &quot;response&quot;) So when all the \\(x\\)s are set to their median, the estimated probability of voting is pi_hat. We could all compute the expected value for all values of a single variable with other variables set to their median. scenarios &lt;- tibble( neweduc = sort(unique(scobit$neweduc)), closing = median(scobit$closing), age = median(scobit$age), south = median(scobit$south), gov = median(scobit$gov)) %&gt;% glimpse() ## Rows: 8 ## Columns: 5 ## $ neweduc &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8 ## $ closing &lt;dbl&gt; 30, 30, 30, 30, 30, 30, 30, 30 ## $ age &lt;dbl&gt; 40, 40, 40, 40, 40, 40, 40, 40 ## $ south &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0 ## $ gov &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0 scenarios$pi_hat &lt;- predict(fit, newdata = scenarios, type = &quot;response&quot;) ggplot(scenarios, aes(x = neweduc, y = pi_hat))+ geom_point() 3.2.2 First Difference Perhaps the most important quantity of interest, though, is the first difference. Imagine two scenario of interest \\(X_{lo}\\) and \\(X_{hi}\\). We then compute the difference \\(\\Delta\\) between the expected values \\(X_{lo}\\) and \\(X_{hi}\\), so that \\(\\hat{\\Delta} = \\hat{E}(y \\mid X_{hi}) - \\hat{E}(y \\mid X_{lo})\\). This works for (almost?) all models we’ll see in this course. lo_scenario &lt;- tibble( neweduc = quantile(scobit$neweduc, 0.10), # 25th percentile closing = median(scobit$closing), age = median(scobit$age), south = median(scobit$south), gov = median(scobit$gov)) %&gt;% glimpse() ## Rows: 1 ## Columns: 5 ## $ neweduc &lt;dbl&gt; 3 ## $ closing &lt;dbl&gt; 30 ## $ age &lt;dbl&gt; 40 ## $ south &lt;dbl&gt; 0 ## $ gov &lt;dbl&gt; 0 hi_scenario &lt;- tibble( neweduc = quantile(scobit$neweduc, 0.90), # 75th percentile closing = median(scobit$closing), age = median(scobit$age), south = median(scobit$south), gov = median(scobit$gov)) %&gt;% glimpse() ## Rows: 1 ## Columns: 5 ## $ neweduc &lt;dbl&gt; 7 ## $ closing &lt;dbl&gt; 30 ## $ age &lt;dbl&gt; 40 ## $ south &lt;dbl&gt; 0 ## $ gov &lt;dbl&gt; 0 fd_hat &lt;- predict(fit, newdata = hi_scenario, type = &quot;response&quot;) - predict(fit, newdata = lo_scenario, type = &quot;response&quot;) print(fd_hat) ## 1 ## 0.4240654 This shows that if we move education from it minimum value (1) to its maximum value (8), the expected value goes up by 0.70. Since the expected value here is a probability, we can say that the chance of voting goes up by 42 percentage points (from 44% to 87%). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
