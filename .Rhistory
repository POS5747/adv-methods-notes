geom_point(position = position_dodge(width = .4))
ci_df <- bind_rows(pbs_ci_df, nbs_ci_df) %>%
glimpse()
ggplot(ci_df, aes(x = est, xmin = lwr, xmax = upr,
y = var, color = type)) +
geom_errorbarh(position = position_dodge(width = .4), height = 0) +
geom_point(position = position_dodge(width = .4))
ci_df <- bind_rows(pbs_ci_df, nbs_ci_df) %>%
glimpse()
ci_df %>%
mutate(ci_chr = paste0("[", scales::number(lwr, 0.001), ", ", scales::number(upr, 0.001), "]"),
est_chr = scales::number(est, 0.001)) %>%
select(var, est_chr, ci_chr, type) %>%
pivot_wider(names_from = type, values_from = ci_chr) %>%
rename(`Variable` = var, `Coefficient Estimate` = est_chr) %>%
kableExtra::kable(format = "markdown")
weisiger <- read_csv("data/weisiger.csv") %>%
glimpse()
# load data from weisiger
weisiger <- read_csv("data/weisiger.csv") %>%
glimpse()
# fit logit model
f <- resist ~ polity_conq + lndist + terrain + soldperterr + gdppc2 + coord
fit <- glm(f, data = weisiger, family = "binomial")
# parametric bs for coefficients
n_bs <- 2000
coef_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
pi_hat <- predict(fit, type = "response")
y_bs <- rbinom(length(pi_hat), size = 1, prob = pi_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
coef_bs[i, ] <- coef(fit_bs)
}
# load data from weisiger
weisiger <- read_csv("data/weisiger.csv") %>%
glimpse()
# fit logit model
f <- resist ~ polity_conq + lndist + terrain + soldperterr + gdppc2 + coord
fit <- glm(f, data = weisiger, family = "binomial")
# parametric bs for coefficients
n_bs <- 2000
coef_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
pi_hat <- predict(fit, type = "response")
y_bs <- rbinom(length(pi_hat), size = 1, prob = pi_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
coef_bs[i, ] <- coef(fit_bs)
}
# parametric bs for coefficients
n_bs <- 100
coef_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
pi_hat <- predict(fit, type = "response")
y_bs <- rbinom(length(pi_hat), size = 1, prob = pi_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
coef_bs[i, ] <- coef(fit_bs)
}
cis <- apply(coef_bs, 2, quantile, probs = c(0.05, 0.95))
pbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Parametric Bootstrap")
# nonparametric bs for coefficients
n_bs <- 2000
# nonparametric bs for coefficients
n_bs <- 100
coef_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
bs_data <- sample_n(weisiger, size = nrow(weisiger), replace = TRUE)  # sample from hks w/ repl.
fit_bs <- update(fit, data = bs_data)                                 # fit same model on resampled data
coef_bs[i, ] <- coef(fit_bs)
}
cis <- apply(coef_bs, 2, quantile, probs = c(0.05, 0.95))
nbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Nonparametric Bootstrap")
nbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Nonparametric Bootstrap")
# combined the two dfs w/ the cis into a single df
ci_df <- bind_rows(pbs_ci_df, nbs_ci_df) %>%
glimpse()
# plots the coefficient estimates and cis
ggplot(ci_df, aes(x = est, xmin = lwr, xmax = upr,
y = var, color = type)) +
geom_errorbarh(position = position_dodge(width = .4), height = 0) +
geom_point(position = position_dodge(width = .4))
cis <- apply(coef_bs, 2, quantile, probs = c(0.1, 0.9))
nbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Nonparametric Bootstrap")
# combined the two dfs w/ the cis into a single df
ci_df <- bind_rows(pbs_ci_df, nbs_ci_df) %>%
glimpse()
# plots the coefficient estimates and cis
ggplot(ci_df, aes(x = est, xmin = lwr, xmax = upr,
y = var, color = type)) +
geom_errorbarh(position = position_dodge(width = .4), height = 0) +
geom_point(position = position_dodge(width = .4))
ge <- ge_raw %>%
select(keep) %>%
na.omit()
# load data from george and epstein
ge_raw <- read_csv("data/ge.csv")
keep <- c("court", "dq", "cr", "pc", "ag", "sp", "pe", "cc", "ap", "dc", "st", "sg")
ge <- ge_raw %>%
select(keep) %>%
na.omit()
ge <- ge_raw %>%
select(all_of(keep)) %>%
na.omit()
# fit logit model
f <- court ~ dq + cr + pc + ag + sp + pe + cc + ap + dc + st + sg
fit <- glm(f, data = ge, family = "binomial")
# parametric bs for coefficients
n_bs <- 100
coef_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
pi_hat <- predict(fit, type = "response")
y_bs <- rbinom(length(pi_hat), size = 1, prob = pi_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
coef_bs[i, ] <- coef(fit_bs)
}
cis <- apply(coef_bs, 2, quantile, probs = c(0.05, 0.95))
pbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Parametric Bootstrap")
# nonparametric bs for coefficients
n_bs <- 100
coef_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
bs_data <- sample_n(ge, size = nrow(ge), replace = TRUE)  # sample from hks w/ repl.
fit_bs <- update(fit, data = bs_data)                                 # fit same model on resampled data
coef_bs[i, ] <- coef(fit_bs)
}
cis <- apply(coef_bs, 2, quantile, probs = c(0.1, 0.9))
nbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Nonparametric Bootstrap")
# load data from george and epstein
ge_raw <- read_csv("data/ge.csv")
keep <- c("court", "dq", "cr", "pc", "ag", "sp", "pe", "cc", "ap", "dc", "st", "sg")
ge <- ge_raw %>%
select(all_of(keep)) %>%
na.omit()
# fit logit model
f <- court ~ dq + cr + pc + ag + sp + pe + cc + ap + dc + st + sg
fit <- glm(f, data = ge, family = "binomial")
# parametric bs for coefficients
n_bs <- 100
coef_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
pi_hat <- predict(fit, type = "response")
y_bs <- rbinom(length(pi_hat), size = 1, prob = pi_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
coef_bs[i, ] <- coef(fit_bs)
}
cis <- apply(coef_bs, 2, quantile, probs = c(0.05, 0.95))
pbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Parametric Bootstrap")
# nonparametric bs for coefficients
n_bs <- 100
coef_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
bs_data <- sample_n(ge, size = nrow(ge), replace = TRUE)  # sample from hks w/ repl.
fit_bs <- update(fit, data = bs_data)                                 # fit same model on resampled data
coef_bs[i, ] <- coef(fit_bs)
}
cis <- apply(coef_bs, 2, quantile, probs = c(0.1, 0.9))
skimr::skim(hks)
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
lambda_hat_lo <- predict(fit, newdata = X_lo)
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
lambda_hat_lo <- predict(fit, newdata = X_lo)
# load hks data
hks <- read_csv("data/hks.csv") %>%
na.omit()
# fit poisson regression model
f <- osvAll ~ troopLag + policeLag + militaryobserversLag +
brv_AllLag + osvAllLagDum + incomp + epduration +
lntpop
# fit poisson regression model
fit <- glm(f, data = hks, family = poisson)
coef(fit)
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
lambda_hat_lo <- predict(fit, newdata = X_lo)
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
lambda_hat_lo <- predict(fit, newdata = X_lo)
hist(hks$troopLag)
quantile(hks$troopLag)
lambda_hat_lo <- predict(fit, newdata = X_lo)
X_hi <- mutate(troopLog = 29.209)
lambda_hat_hi <- predict(fit, newdata = X_hi)
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
lambda_hat_lo <- predict(fit, newdata = X_lo)
X_hi <- mutate(troopLog = 29.209)
lambda_hat_hi <- predict(fit, newdata = X_hi)
# fit poisson regression model
fit <- glm(f, data = hks, family = poisson)
coef(fit)
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
lambda_hat_lo <- predict(fit, newdata = X_lo)
X_hi <- mutate(troopLog = 29.209)
X_hi <- mutate(X_lo, troopLog = 29.209)
lambda_hat_hi <- predict(fit, newdata = X_hi)
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
X_hi <- mutate(X_lo, troopLog = 29.209)
lambda_hat_hi <- predict(fit, newdata = X_hi)
fd_hat <- lambda_hat_hi - lambda_hat_lo
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat), size = 1, prob = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit, newdata = X_lo)
lh_hi_bs <- predict(fit, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit, newdata = X_lo)
lh_hi_bs <- predict(fit, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit, newdata = X_lo)
lh_hi_bs <- predict(fit, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
cis <- quantile(fd_bs, probs = c(0.05, 0.95))
cis
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
X_hi <- mutate(X_lo, troopLog = 29.209)
lambda_hat_hi <- predict(fit, newdata = X_hi)
fd_hat <- lambda_hat_hi - lambda_hat_lo
# parametric bs for coefficients
n_bs <- 100
fd_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit, newdata = X_lo)
lh_hi_bs <- predict(fit, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
cis <- quantile(fd_bs, probs = c(0.05, 0.95))
cis
X_hi
X_hi <- mutate(X_lo, troopLag = 29.209)
lambda_hat_hi <- predict(fit, newdata = X_hi)
fd_hat <- lambda_hat_hi - lambda_hat_lo
# compute qi using the invariance property
X_lo <- tibble(troopLag = 0,
policeLag = 0,
militaryobserversLag = 0,
brv_AllLag = 0,
osvAllLagDum = 0,
incomp = 2,
epduration = 46,
lntpop = 9.19)
X_hi <- mutate(X_lo, troopLag = 29.209)
lambda_hat_hi <- predict(fit, newdata = X_hi)
fd_hat <- lambda_hat_hi - lambda_hat_lo
# parametric bs for coefficients
n_bs <- 100
fd_bs <- matrix(nrow = n_bs, ncol = length(coef(fit)))
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit, newdata = X_lo)
lh_hi_bs <- predict(fit, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit, newdata = X_lo)
lh_hi_bs <- predict(fit, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
cis <- quantile(fd_bs, probs = c(0.05, 0.95))
pbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Parametric Bootstrap")
cis <- quantile(fd_bs, probs = c(0.05, 0.95))
cis
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
cis <- quantile(fd_bs, probs = c(0.05, 0.95))
cis
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
cis <- quantile(fd_bs, probs = c(0.05, 0.95))
pbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Parametric Bootstrap")
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs <- lh_hi_bs - lh_lo_bs
}
cis <- quantile(fd_bs, probs = c(0.05, 0.95))
cis <- quantile(fd_bs, probs = c(0.05, 0.95))
cis <- quantile(fd_bs, probs = c(0.05, 0.95)); cis
fs_bs
fd_bs
fd_bs <- numeric(n_bs)
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs[i] <- lh_hi_bs - lh_lo_bs
}
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs[i] <- lh_hi_bs - lh_lo_bs
}
cis <- quantile(fd_bs, probs = c(0.05, 0.95)); cis
pbs_ci_df <- tibble(var = names(coef(fit)),
est = coef(fit),
lwr = cis["5%", ],
upr = cis["95%", ],
type = "Parametric Bootstrap")
cis <- quantile(fd_bs, probs = c(0.05, 0.95)); cis
# nonparametric bs for coefficients
n_bs <- 100
fd_bs <- numeric(n_bs)
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
bs_data <- sample_n(ge, size = nrow(ge), replace = TRUE)  # sample from hks w/ repl.
fit_bs <- update(fit, data = bs_data)                                 # fit same model on resampled data
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs[i] <- lh_hi_bs - lh_lo_bs
}
bs_data <- sample_n(hks, size = nrow(hks), replace = TRUE)  # sample from hks w/ repl.
fit_bs <- update(fit, data = bs_data)                                 # fit same model on resampled data
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs[i] <- lh_hi_bs - lh_lo_bs
for (i in 1:n_bs) {
bs_data <- sample_n(hks, size = nrow(hks), replace = TRUE)  # sample from hks w/ repl.
fit_bs <- update(fit, data = bs_data)                                 # fit same model on resampled data
lh_lo_bs <- predict(fit_bs, newdata = X_lo)
lh_hi_bs <- predict(fit_bs, newdata = X_hi)
fd_bs[i] <- lh_hi_bs - lh_lo_bs
}
n <- 100
lambda_tilde <- rgamma(n, 3, 2)
y_tilde <- rpois(n, lambda = lambda_tilde)
arm::display(fit)
texreg::screenreg(fit)
# nonparametric bs for coefficients
n_bs <- 1000
fd_bs <- numeric(n_bs)
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
bs_data <- sample_n(hks, size = nrow(hks), replace = TRUE)  # sample from hks w/ repl.
fit_bs <- update(fit, data = bs_data)                       # fit same model on resampled data
lh_lo_bs <- predict(fit_bs, newdata = X_lo, type = "response")
lh_hi_bs <- predict(fit_bs, newdata = X_hi, type = "response")
fd_bs[i] <- lh_hi_bs - lh_lo_bs
}
quantile(fd_bs, probs = c(0.05, 0.95))
# parametric bs for coefficients
n_bs <- 1000
fd_bs <- numeric(n_bs)
names(coef_bs) <- names(coef(fit))
for (i in 1:n_bs) {
lambda_hat <- predict(fit, type = "response")
y_bs <- rpois(length(lambda_hat),  lambda = lambda_hat)
fit_bs <- update(fit, formula = y_bs ~ .)
lh_lo_bs <- predict(fit_bs, newdata = X_lo, type = "response")
lh_hi_bs <- predict(fit_bs, newdata = X_hi, type = "response")
fd_bs[i] <- lh_hi_bs - lh_lo_bs
}
quantile(fd_bs, probs = c(0.05, 0.95))
library(tidyverse)
