plogis(X%*%beta)
beta <- rep(-1, ncol(X))
plogis(X%*%beta)
beta <- rep(-.1, ncol(X))
beta
plogis(X%*%beta)
beta <- rep(-.01, ncol(X))
plogis(X%*%beta)
beta <- rep(-.001, ncol(X))
plogis(X%*%beta)
sum(y*log(p)) + sum((1 - y)*log(1 - p))
p <- plogis(X%*%beta)  # pi is special in R, so I use p
ll <- sum(y*log(p)) + sum((1 - y)*log(1 - p))
ll
?plogis
# create formula
f <- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov
# obtain the model matrix X
mf <- model.frame(f, data = scobit)  # model frame
# obtain the outcome variable y
y <- model.response(mf)
par_start <- rep(0, ncol(X))
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1))
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1))
opt$par
coef(glm.fit(X, y, family = binomial()))
?optim
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1), method = "BFGS")
opt$par
coef(glm.fit(X, y, family = binomial()))
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1), method = "CG")
opt$par
X%*%beta
plogis(X%*%beta)
logit_ll <- function(beta, y, X) {
p <- plogis(X%*%beta)  # pi is special in R, so I use p
ll <- sum(y*log(p)) + sum((1 - y)*log(1 - p))
return(ll)
}
# alternatively
logit_ll2 <- function(beta, y, X) {
p <- plogis(X%*%beta)
ll <- sum(dbinom(y, size = 1, prob = p, log = TRUE))  # easier to use R's d*() functions
return(ll)
}
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1, reltol = .Machine$double.eps),
method = "BFGS")
opt$par
opt
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -.001, reltol = .Machine$double.eps),
method = "BFGS")
opt$par
par_start <- c(-2, rep(0, ncol(X) - 1)
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
par_start <- c(-2, rep(0, ncol(X) - 1))
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -.001, reltol = .Machine$double.eps),
method = "BFGS")
opt$par
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1, reltol = .Machine$double.eps),
method = "BFGS")
opt$par
coef(glm.fit(X, y, family = binomial()))
fit <- glm(f, data = scobit, family = "binomial")
coef(fit)
logit_ll <- function(beta, y, X) {
p <- plogis((X%*%(beta*1000))/1000)  # pi is special in R, so I use p
ll <- sum(y*log(p)) + sum((1 - y)*log(1 - p))
return(ll)
}
# create formula
f <- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov
# obtain the model matrix X
mf <- model.frame(f, data = scobit)  # model frame
# obtain the outcome variable y
y <- model.response(mf)
# for some reason, this isn't converging
par_start <- c(-3, rep(0, ncol(X) - 1))
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1, reltol = .Machine$double.eps),
method = "BFGS")
opt$par
logit_ll <- function(beta, y, X) {
p <- plogis((X%*%(beta*100000))/100000)  # pi is special in R, so I use p
ll <- sum(y*log(p)) + sum((1 - y)*log(1 - p))
return(ll)
}
# alternatively
logit_ll2 <- function(beta, y, X) {
p <- plogis(X%*%beta)
ll <- sum(dbinom(y, size = 1, prob = p, log = TRUE))  # easier to use R's d*() functions
return(ll)
}
# alternatively
logit_ll2 <- function(beta, y, X) {
p <- plogis(X%*%beta)
ll <- sum(dbinom(y, size = 1, prob = p, log = TRUE))  # easier to use R's d*() functions
return(ll)
}
The tricky part about using `optim()` here is not the log-likelihood function, but setting up `X` and `y`. The code below creates the outcome vector $y$ and the matrix $X$ of explanatory variables (with a leading columns of 1s).
```{r}
# create formula
f <- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov
# obtain the model matrix X
mf <- model.frame(f, data = scobit)  # model frame
# obtain the outcome variable y
y <- model.response(mf)
# obtain the outcome variable y
y <- model.response(mf)
Then we can use `optim()`.
```{r}
# for some reason, this isn't converging
par_start <- c(-3, rep(0, ncol(X) - 1))
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1, reltol = .Machine$double.eps),
method = "BFGS")
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1, reltol = .Machine$double.eps),
method = "BFGS")
opt$par
coef(glm.fit(X, y, family = binomial()))
logit_ll <- function(beta, y, X) {
p <- plogis(X%*%beta)  # pi is special in R, so I use p
ll <- sum(y*log(p)) + sum((1 - y)*log(1 - p))
return(ll)
}
# alternatively
logit_ll2 <- function(beta, y, X) {
p <- plogis(X%*%beta)
ll <- sum(dbinom(y, size = 1, prob = p, log = TRUE))  # easier to use R's d*() functions
return(ll)
}
# alternatively
logit_ll2 <- function(beta, y, X) {
p <- plogis(X%*%beta)
ll <- sum(dbinom(y, size = 1, prob = p, log = TRUE))  # easier to use R's d*() functions
return(ll)
}
# alternatively
logit_ll2 <- function(beta, y, X) {
p <- plogis(X%*%beta)
ll <- sum(dbinom(y, size = 1, prob = p, log = TRUE))  # easier to use R's d*() functions
return(ll)
}
# alternatively
logit_ll2 <- function(beta, y, X) {
ll <- sum(dbinom(y, size = 1, prob = plogis(X%*%beta), log = TRUE))  # easier to use R's d*() functions
return(ll)
}
# create formula
f <- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov
# obtain the model matrix X
mf <- model.frame(f, data = scobit)  # model frame
# for some reason, this isn't converging
par_start <- c(-3, rep(0, ncol(X) - 1))
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1, reltol = .Machine$double.eps),
method = "BFGS")
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1, reltol = .Machine$double.eps),
method = "BFGS")
opt$par
coef(glm.fit(X, y, family = binomial()))
opt$par
coef(glm.fit(X, y, family = binomial()))
opt <- optim(par_start, fn = logit_ll2, y = y, X = X,
control = list(fnscale = -1, reltol = .Machine$double.eps),
method = "BFGS")
opt$par
y
length(y)
length(p)
rmarkdown::clean_site(preview = FALSE)
# create log-likelihood
poisson_ll <- function(beta, y, X) {
lambda <- exp(X%*%beta)
ll <- sum(dpois(y, lambda = lambda, log = TRUE))
return(ll)
}
# load hks data
hks <- read_csv("data/hks.csv") %>%
na.omit()
# create X and y
f <- osvAll ~ troopLag + policeLag + militaryobserversLag +
brv_AllLag + osvAllLagDum + incomp + epduration +
lntpop
mf <- model.frame(f, data = hks)  # model frame
X <- model.matrix(f, mf)          # model matrix X
y <- model.response(mf)           # outcome variable y
par_start <- rep(0, ncol(X))
# this poisson model is so bad that optim has a bit of trouble
# intutitively, there's a single outlier that basically makes
# all poissons nearly impossible.
opt <- optim(par_start, fn = poisson_ll, y = y, X = X,
control = list(fnscale = -1))
opt$par
library(rstanarm)
library(tidybayes)
small_scobit <- sample_n(scobit, 1000)  # subsample b/c model is slow
stan_fit <- stan_glm(f, data = small_scobit, family = "binomial")
# load hks data
hks <- read_csv("data/hks.csv") %>%
na.omit()
# create X and y
f <- osvAll ~ troopLag + policeLag + militaryobserversLag +
brv_AllLag + osvAllLagDum + incomp + epduration +
lntpop
# load hks data
hks <- read_csv("data/hks.csv") %>%
na.omit()
# fit poisson model
f <- osvAll ~ troopLag + policeLag + militaryobserversLag +
brv_AllLag + osvAllLagDum + incomp + epduration +
lntpop
fit <- glm(f, data = hks, family = poisson)
# simulate fake data from predictive distribution
observed_data <- hks %>%
mutate(type = "observed",
linpred_hat = predict(fit, type = "link"))
sim_list <- list()
for (i in 1:5) {
sim_list[[i]] <- observed_data %>%
mutate(osvAll = rpois(nrow(observed_data),
lambda = exp(observed_data$linpred_hat)),
type = paste0("simulated #", i))
}
gg_data <- bind_rows(sim_list) %>%
bind_rows(observed_data) %>%
glimpse()
# plot fake and observed data against linear predictor
ggplot(gg_data, aes(x = linpred_hat, y = osvAll + 1)) +
geom_point(alpha = 0.1, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
scale_y_log10()
ggplot(gg_data, aes(x = troopLag, y = osvAll + 1)) +
geom_point(alpha = 0.3, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
scale_y_log10() +
geom_smooth(se = FALSE)
library(rstanarm); options(mc.cores = parallel::detectCores())
library(tidybayes)
stan_fit <- stan_glm(f, data = hks, family = "poisson")
ppd <- hks %>%
add_predicted_draws(stan_fit, ndraws = 8) %>%
mutate(.draw = paste0("Draw #", .draw)) %>%
pivot_wider(names_from = .draw, values_from = .prediction) %>%
mutate(`Observed` = osvAll) %>%
pivot_longer(`Draw #1`:`Observed`, names_to = "type", values_to = "osvAll2") %>%
glimpse()
ggplot(ppd, aes(x = troopLag, y = osvAll2 + 1)) +
geom_point(alpha = 0.2, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
geom_smooth(se = FALSE) +
scale_y_log10()
library(tidyverse)
scobit <- haven::read_dta("data/scobit.dta") %>%
filter(newvote != -1) %>%  # weird -1s in data; unsure if sufficient
glimpse()
f <- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov
fit <- glm(f, data = scobit, family = "binomial")
# compute estimates of linear predictor and pi
linpred_hat <- predict(fit, type = "link")  # on scale of linear predictor
pi_hat <- predict(fit, type = "response")   # on probability scale
# put observed data into a data frame with linpred and pi ests
observed_data <- scobit %>%
mutate(type = "observed",
linpred_hat = linpred_hat,
pi_hat = pi_hat)
# create data frames with simulated data from predictive distribution
sim_list <- list()
for (i in 1:5) {
y_tilde <- rbinom(nrow(observed_data), size = 1, prob = pi_hat)
sim_list[[i]] <- observed_data %>%
mutate(newvote = y_tilde,
type = paste0("simulated #", i))
}
# bind data together
gg_data <- bind_rows(sim_list) %>%
bind_rows(observed_data) %>%
glimpse()
# plot fake and obs data against linear predictor.
ggplot(gg_data, aes(x = linpred_hat, y = newvote)) +
geom_jitter(height = 0.05, alpha = 0.01, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
geom_smooth()
# plot fake and obs data against age.
ggplot(gg_data, aes(x = age, y = newvote)) +
geom_jitter(height = 0.05, alpha = 0.01, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
geom_smooth(se = FALSE)
f <- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + age + south + gov
fit <- glm(f, data = scobit, family = "binomial")
observed_data <- scobit %>%
mutate(type = "observed",
linpred_hat = predict(fit, type = "link"))
sim_list <- list()
for (i in 1:5) {
y_tilde <- rbinom(nrow(observed_data), size = 1, prob = plogis(observed_data$linpred_hat))
sim_list[[i]] <- observed_data %>%
mutate(newvote = y_tilde,
type = paste0("simulated #", i))
}
gg_data <- bind_rows(sim_list) %>%
bind_rows(observed_data) %>%
glimpse()
ggplot(gg_data, aes(x = age, y = newvote)) +
geom_jitter(height = 0.05, alpha = 0.01, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
geom_smooth(se = FALSE)
library(rstanarm); options(mc.cores = parallel::detectCores())
small_scobit <- sample_n(scobit, 1000)  # subsample b/c model is slow
stan_fit <- stan_glm(f, data = small_scobit, family = "binomial")
library(tidybayes)
ppd <- small_scobit %>%
add_predicted_draws(stan_fit, ndraws = 8) %>%
mutate(.draw = paste0("Draw #", .draw)) %>%
pivot_wider(names_from = .draw, values_from = .prediction) %>%
mutate(`Observed` = newvote) %>%
pivot_longer(`Draw #1`:`Observed`, names_to = "type", values_to = "newvote2") %>%
glimpse()
ggplot(ppd, aes(x = age, y = newvote2)) +
geom_jitter(height = 0.15, alpha = 0.2, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
geom_smooth(se = FALSE)
# load hks data
hks <- read_csv("data/hks.csv") %>%
na.omit()
# fit poisson model
f <- osvAll ~ troopLag + policeLag + militaryobserversLag +
brv_AllLag + osvAllLagDum + incomp + epduration +
lntpop
fit <- glm(f, data = hks, family = poisson)
# simulate fake data from predictive distribution
observed_data <- hks %>%
mutate(type = "observed",
linpred_hat = predict(fit, type = "link"))
sim_list <- list()
for (i in 1:5) {
sim_list[[i]] <- observed_data %>%
mutate(osvAll = rpois(nrow(observed_data),
lambda = exp(observed_data$linpred_hat)),
type = paste0("simulated #", i))
}
gg_data <- bind_rows(sim_list) %>%
bind_rows(observed_data) %>%
glimpse()
# plot fake and observed data against linear predictor
ggplot(gg_data, aes(x = linpred_hat, y = osvAll + 1)) +
geom_point(alpha = 0.1, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
scale_y_log10()
# plot fake and observed data against number of troops
ggplot(gg_data, aes(x = troopLag, y = osvAll + 1)) +
geom_point(alpha = 0.3, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
scale_y_log10() +
geom_smooth(se = FALSE)
stan_fit <- stan_glm(f, data = hks, family = "poisson", chains = 1)
ppd <- hks %>%
add_predicted_draws(stan_fit, ndraws = 8) %>%
mutate(.draw = paste0("Draw #", .draw)) %>%
pivot_wider(names_from = .draw, values_from = .prediction) %>%
mutate(`Observed` = osvAll) %>%
pivot_longer(`Draw #1`:`Observed`, names_to = "type", values_to = "osvAll2") %>%
glimpse()
ggplot(ppd, aes(x = troopLag, y = osvAll2 + 1)) +
geom_point(alpha = 0.2, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
geom_smooth(se = FALSE) +
scale_y_log10()
ppd <- hks %>%
add_predicted_draws(stan_fit, ndraws = 8) %>%
mutate(.draw = paste0("Draw #", .draw)) %>%
pivot_wider(names_from = .draw, values_from = .prediction) %>%
mutate(`Observed` = osvAll) %>%
pivot_longer(`Draw #1`:`Observed`, names_to = "type", values_to = "osvAll2") %>%
glimpse()
ggplot(ppd, aes(x = troopLag, y = osvAll2 + 1)) +
geom_point(alpha = 0.2, shape = 21, size = 0.3) +
facet_wrap(vars(type)) +
geom_smooth(se = FALSE) +
scale_y_log10()
# start by getting a data frame with all the necessary variables
vars <- get_all_vars(f, data = scobit)[, -1]  # model frame
scobit <- haven::read_dta("data/scobit.dta") %>%
filter(newvote != -1)
scobit <- haven::read_dta("data/scobit.dta") %>%
filter(newvote != -1)
f <- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov
f <- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov
fit <- glm(f, data = scobit, family = binomial)
# start by getting a data frame with all the necessary variables
vars <- get_all_vars(f, data = scobit)[, -1]  # model frame
vars
scenario <- tibble(
neweduc = median(scobit$neweduc),
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)
)
scenario <- tibble(
neweduc = median(scobit$neweduc),
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
# now use the predict() function to get pi_hat
pi_hat <- predict(fit, newdata = medians, type = "response")
# now use the predict() function to get pi_hat
pi_hat <- predict(fit, newdata = scenario, type = "response")
scenarios <- tibble(
neweduc = sort(unique(scobit$neweduc)),
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
scenarios$pi_hat <- predict(fit, newdata = educ, type = "response")
ggplot(scenarios, aes(x = neweduc, y = pi_hat))+
geom_point()
scenarios <- tibble(
neweduc = sort(unique(scobit$neweduc)),
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
scenarios$pi_hat <- predict(fit, newdata = educ, type = "response")
scenarios$pi_hat <- predict(fit, newdata = scenarios, type = "response")
ggplot(scenarios, aes(x = neweduc, y = pi_hat))+
geom_point()
scenarios <- tibble(
neweduc = sort(unique(scobit$neweduc)),
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
scenarios$pi_hat <- predict(fit, newdata = scenarios, type = "response")
ggplot(scenarios, aes(x = neweduc, y = pi_hat))+
geom_point()
hi_scenario <- tibble(
neweduc = quantile(scobit$neweduc, 0.75), # 75th percentile
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
lo_scenario <- tibble(
neweduc = quantile(scobit$neweduc, 0.25), # 25th percentile
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
hi_scenario <- tibble(
neweduc = quantile(scobit$neweduc, 0.75), # 75th percentile
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
lo_scenario <- tibble(
neweduc = quantile(scobit$neweduc, 0.10), # 25th percentile
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
hi_scenario <- tibble(
neweduc = quantile(scobit$neweduc, 0.90), # 75th percentile
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
lo_scenario <- tibble(
neweduc = quantile(scobit$neweduc, 0.10), # 25th percentile
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
hi_scenario <- tibble(
neweduc = quantile(scobit$neweduc, 0.90), # 75th percentile
closing = median(scobit$closing),
age = median(scobit$age),
south = median(scobit$south),
gov = median(scobit$gov)) %>%
glimpse()
fd_hat <- predict(fit, newdata = hi_scenario, type = "response") -
predict(fit, newdata = lo_scenario, type = "response")
print(fd_hat)
predict(fit, newdata = hi_scenario, type = "response")
predict(fit, newdata = lo_scenario, type = "response")
print(fd_hat)
?predict
# for some reason, this isn't converging
par_start <- c(-3, rep(0, ncol(X) - 1))
opt <- optim(par_start, fn = logit_ll), y = y, X = X,
opt <- optim(par_start, fn = logit_ll, y = y, X = X,
control = list(fnscale = -1))
rmarkdown::clean_site(preview = FALSE)
